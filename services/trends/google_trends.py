import os
import pandas as pd
import pandas_gbq
from google.oauth2 import service_account
from datetime import datetime, timedelta
from database_config import TrendsCache
from dotenv import load_dotenv
from utils.logger_config import get_logger

# ç’°å¢ƒå¤‰æ•°ã‚’æ˜ç¤ºçš„ã«èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚¬ãƒ¼ã®åˆæœŸåŒ–
logger = get_logger(__name__)

class GoogleTrendsManager:
    """Google Trendsã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ãƒ»ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        import json
        import base64
        
        self.project_id = os.getenv('GOOGLE_CLOUD_PROJECT_ID')
        self.db = TrendsCache()
        self.credentials = None
        
        # æ–¹æ³•1: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸèªè¨¼æƒ…å ±ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆæœ¬ç•ªç’°å¢ƒç”¨ï¼‰
        credentials_content = os.getenv('GOOGLE_APPLICATION_CREDENTIALS_CONTENT')
        if credentials_content:
            try:
                # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
                decoded_content = base64.b64decode(credentials_content).decode('utf-8')
                credentials_dict = json.loads(decoded_content)
                self.credentials = service_account.Credentials.from_service_account_info(credentials_dict)
                logger.info("  Credentials: GOOGLE_APPLICATION_CREDENTIALS_CONTENTã‹ã‚‰èª­ã¿è¾¼ã¿æ¸ˆã¿")
            except Exception as e:
                logger.error(f"âŒ Google Trends Credentials (CONTENT) èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                self.credentials = None
        
        # æ–¹æ³•2: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒç”¨ï¼‰
        if not self.credentials:
            credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
            if credentials_path:
                if os.path.exists(credentials_path):
                    try:
                        self.credentials = service_account.Credentials.from_service_account_file(credentials_path)
                        logger.info(f"  Credentials: ãƒ•ã‚¡ã‚¤ãƒ« {credentials_path} ã‹ã‚‰èª­ã¿è¾¼ã¿æ¸ˆã¿")
                    except Exception as e:
                        logger.error(f"âŒ Google Trends Credentials èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                        self.credentials = None
                else:
                    logger.warning(f"âš ï¸ Google Trends Credentials: ãƒ‘ã‚¹ãŒå­˜åœ¨ã—ã¾ã›ã‚“ ({credentials_path})")
            else:
                logger.warning("âš ï¸ Google Trends Credentials: GOOGLE_APPLICATION_CREDENTIALS ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        if not self.project_id:
            logger.warning("Warning: GOOGLE_CLOUD_PROJECT_IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        logger.info(f"Google Trends ManageråˆæœŸåŒ–:")
        logger.info(f"  Project ID: {'è¨­å®šæ¸ˆã¿' if self.project_id else 'æœªè¨­å®š'}")
        logger.info(f"  Credentials: {'è¨­å®šæ¸ˆã¿' if self.credentials else 'æœªè¨­å®š'}")
    
    def get_trends(self, region='JP', limit=25, force_refresh=False):
        """Google Trendsã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å„ªå…ˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§BigQueryï¼‰"""
        if force_refresh:
            logger.info(f"ğŸ”„ Google Trends force_refresh: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™")
            self.db.clear_google_trends_cache(region)
        
        # æ—¥æœ¬ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å„ªå…ˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§BigQueryï¼‰
        return self.get_cached_trends(region, limit, force_refresh)
    
    def get_bigquery_trends(self, region='JP', limit=25):
        """BigQueryã‹ã‚‰Google Trendsãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            logger.info(f"=== Google Trends BigQueryå–å¾—é–‹å§‹ ===")
            logger.info(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: region={region}, limit={limit}")
            
            if not self.project_id:
                return {
                    'success': False,
                    'error': 'Google Cloud Project IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“',
                    'data': []
                }
            
            # USãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã®ã¿ã«é›†ä¸­
            logger.info("USãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™")
            
            # USãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯top_termsãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½¿ç”¨
            if region == 'US':
                logger.info(f"{region}ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ãŸã‚ã€top_termsãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
                query = f"""
            SELECT 
                term as keyword,
                AVG(score) as score,
                'US' as country_code,
                refresh_date,
                ROW_NUMBER() OVER (ORDER BY AVG(score) DESC) as rank
            FROM `bigquery-public-data.google_trends.top_terms`
            WHERE refresh_date = (
                SELECT MAX(refresh_date)
                FROM `bigquery-public-data.google_trends.top_terms`
            )
              AND score IS NOT NULL
            GROUP BY term, refresh_date
            ORDER BY score DESC
            LIMIT {limit}
            """
            else:
                # æ—¥æœ¬ã¨åŒã˜ã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ï¼ˆå›½ã‚³ãƒ¼ãƒ‰ã‚’æŒ‡å®šï¼‰
                logger.info(f"{region}ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ãŸã‚ã€international_top_termsãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
                query = f"""
            SELECT 
                term as keyword,
                AVG(score) as score,
                country_code,
                refresh_date,
                ROW_NUMBER() OVER (ORDER BY AVG(score) DESC) as rank
            FROM `bigquery-public-data.google_trends.international_top_terms`
            WHERE country_code = '{region}'
              AND refresh_date = (
                SELECT MAX(refresh_date)
                FROM `bigquery-public-data.google_trends.international_top_terms`
                WHERE country_code = '{region}'
              )
              AND score IS NOT NULL
            GROUP BY term, country_code, refresh_date
            ORDER BY score DESC
            LIMIT {limit}
            """
            
            logger.debug(f"BigQueryã‚¯ã‚¨ãƒªå®Ÿè¡Œ: {query}")
            
            # BigQueryã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            df = pandas_gbq.read_gbq(query, project_id=self.project_id, credentials=self.credentials)
            
            if df.empty:
                logger.warning("âŒ Google Trends: USãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return {
                    'success': False,
                    'error': 'USãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ',
                    'data': [],
                    'status': 'api_error',
                    'source': 'BigQuery',
                    'country': region
                }
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
            trends_data = []
            logger.debug(f"å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ç¢ºèª:")
            logger.debug(f"åˆ—å: {df.columns.tolist()}")
            logger.debug(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å½¢çŠ¶: {df.shape}")
            logger.debug(f"æœ€åˆã®5è¡Œ: {df.head(5).to_dict('records')}")
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            unique_keywords = df['keyword'].nunique()
            logger.debug(f"ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°: {unique_keywords}")
            
            # é‡è¤‡ã‚’æ’é™¤ï¼ˆå¿µã®ãŸã‚ï¼‰
            seen_keywords = set()
            
            for i, row in df.iterrows():
                keyword = str(row['keyword']).strip()
                if not keyword or keyword == 'nan' or keyword in seen_keywords:
                    continue
                    
                seen_keywords.add(keyword)
                
                # Googleæ¤œç´¢URLã‚’ç”Ÿæˆ
                google_search_url = f"https://www.google.com/search?q={keyword.replace(' ', '+')}&geo=US"
                
                trends_data.append({
                    'keyword': keyword,
                    'rank': len(trends_data) + 1,  # é€£ç•ªã§ãƒ©ãƒ³ã‚¯ã‚’è¨­å®š
                    'popularity': int(row['score']),
                    'score': int(row['score']),
                    'country_code': row['country_code'],
                    'refresh_date': row['refresh_date'].strftime('%Y-%m-%d') if pd.notna(row['refresh_date']) else None,
                    'google_search_url': google_search_url
                })
                
                # æœ€åˆã®3ä»¶ã ã‘ãƒ­ã‚°å‡ºåŠ›
                if len(trends_data) <= 3:
                    logger.debug(f"è¡Œ {len(trends_data)}: keyword='{keyword}', rank={len(trends_data)}, score={row['score']}")
                    logger.debug(f"  å¤‰æ›å¾Œ: rank={len(trends_data)}, popularity={int(row['score'])}")
            
            logger.info(f"âœ… Google Trends: {len(trends_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ (å›½ã‚³ãƒ¼ãƒ‰: {region})")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self.db.save_google_trends_to_cache(trends_data, region)
            
            return {
                'success': True,
                'data': trends_data,
                'status': 'success',
                'source': 'BigQuery',
                'country': region,
                'actual_country': region,  # å®Ÿéš›ã«ä½¿ç”¨ã•ã‚ŒãŸå›½ã‚³ãƒ¼ãƒ‰
                'total_count': len(trends_data)
            }
            
        except Exception as e:
            logger.error(f"âŒ Google Trends BigQueryå–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {
                'success': False,
                'error': f'Google Trendså–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}',
                'data': [],
                'status': 'api_error',
                'source': 'BigQuery',
                'country': region,
                'debug_info': {
                    'error_type': type(e).__name__,
                    'error_message': str(e)
                }
            }
    
    def get_cached_trends(self, region='JP', limit=25, force_refresh=False):
        """Google Trendsãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ã¿å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã—ï¼‰"""
        try:
            logger.info(f"=== Google Trends ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—é–‹å§‹ ===")
            logger.info(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: region={region}, limit={limit}, force_refresh={force_refresh}")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å–å¾—
            cached_data = self.db.get_google_trends_from_cache(region)
            
            if cached_data:
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã«æ¤œç´¢URLã‚’è¿½åŠ 
                for item in cached_data:
                    if 'google_search_url' not in item and 'keyword' in item:
                        keyword = item['keyword']
                        item['google_search_url'] = f"https://www.google.com/search?q={keyword.replace(' ', '+')}"
                
                logger.info(f"âœ… Google Trends: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰{len(cached_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
                return {
                    'success': True,
                    'data': cached_data,
                    'status': 'cached',
                    'source': 'database_cache',
                    'total_count': len(cached_data)
                }
            else:
                # force_refresh=Falseã®å ´åˆã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„å ´åˆã§ã‚‚å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã•ãªã„
                if not force_refresh:
                    logger.warning("âš ï¸ Google Trends: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ãŒã€force_refresh=falseã®ãŸã‚å¤–éƒ¨APIã¯å‘¼ã³å‡ºã—ã¾ã›ã‚“")
                    return {
                        'success': False,
                        'data': [],
                        'status': 'cache_not_found',
                        'source': 'database_cache',
                        'error': 'ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“'
                    }
                # force_refresh=trueã®å ´åˆã®ã¿å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã™
                logger.warning("âš ï¸ Google Trends: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã—ã¾ã™")
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ã¿å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã—
                result = self.get_bigquery_trends(region, limit)
                if result.get('success') and result.get('data'):
                    logger.info(f"âœ… Google Trends: å¤–éƒ¨APIã‹ã‚‰{len(result['data'])}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸ")
                    return {
                        'success': True,
                        'data': result['data'],
                        'status': 'api_fetched',
                        'source': 'BigQuery',
                        'total_count': len(result['data'])
                    }
                else:
                    logger.error(f"âŒ Google Trends: å¤–éƒ¨APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    return {
                        'success': False,
                        'data': [],
                        'status': 'api_error',
                        'source': 'BigQuery',
                        'total_count': 0
                    }
                
        except Exception as e:
            logger.error(f"âŒ Google Trends ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {
                'success': False,
                'error': f'Google Trendså–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}',
                'data': []
            }
    

