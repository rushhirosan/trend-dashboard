import requests
from datetime import datetime
from database_config import TrendsCache
from utils.logger_config import get_logger
from utils.rate_limiter import get_rate_limiter

# ãƒ­ã‚¬ãƒ¼ã®åˆæœŸåŒ–
logger = get_logger(__name__)

class HackerNewsTrendsManager:
    """Hacker Newsã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ãƒ»ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.base_url = "https://hacker-news.firebaseio.com/v0"
        self.db = TrendsCache()
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™: Hacker News APIã¯ç‰¹ã«åˆ¶é™ãªã—ã ãŒã€ä¿å®ˆçš„ã«10ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/åˆ†ã«è¨­å®š
        self.rate_limiter = get_rate_limiter('hackernews', max_requests=10, window_seconds=60)
        
        logger.info(f"Hacker News Trends ManageråˆæœŸåŒ–:")
        logger.info(f"  Base URL: {self.base_url}")
    
    def get_trends(self, story_type='top', limit=25, force_refresh=False):
        """Hacker Newsãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å„ªå…ˆï¼‰"""
        try:
            if force_refresh:
                logger.info(f"ğŸ”„ Hacker News force_refresh: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™")
                self.db.clear_hackernews_trends_cache(story_type)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            cached_data = self.db.get_hackernews_trends_from_cache(story_type)
            
            if cached_data:
                # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
                cached_data.sort(key=lambda x: x.get('score', 0), reverse=True)
                
                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å†è¨­å®š
                for i, item in enumerate(cached_data, 1):
                    item['rank'] = i
                
                logger.info(f"âœ… Hacker News: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰{len(cached_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆã—ã¾ã—ãŸ")
                return {
                    'success': True,
                    'data': cached_data,
                    'status': 'cached',
                    'source': 'database_cache',
                    'story_type': story_type
                }
            else:
                logger.warning("âš ï¸ Hacker News: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã—ã¾ã™")
                return self.get_top_stories(story_type, limit)
                
        except Exception as e:
            logger.error(f"âŒ Hacker News ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {'error': f'Hacker Newsãƒˆãƒ¬ãƒ³ãƒ‰ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}', 'success': False}
    
    def get_top_stories(self, story_type='top', limit=25):
        """Hacker Newsã®ãƒˆãƒƒãƒ—ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’å–å¾—"""
        try:
            logger.info(f"Hacker News APIå‘¼ã³å‡ºã—é–‹å§‹ (type: {story_type}, limit: {limit})")
            
            # ã‚¹ãƒˆãƒ¼ãƒªãƒ¼IDã®ãƒªã‚¹ãƒˆã‚’å–å¾—
            story_list_url = f"{self.base_url}/{story_type}stories.json"
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯
            self.rate_limiter.wait_if_needed()
            
            response = requests.get(story_list_url, timeout=10)
            
            if response.status_code != 200:
                return {
                    'error': f'Hacker News API ã‚¨ãƒ©ãƒ¼: {response.status_code}',
                    'success': False
                }
            
            story_ids = response.json()[:limit]
            logger.debug(f"å–å¾—ã—ãŸã‚¹ãƒˆãƒ¼ãƒªãƒ¼IDæ•°: {len(story_ids)}")
            
            # å„ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®è©³ç´°ã‚’å–å¾—
            stories = []
            for story_id in story_ids:
                try:
                    story_url = f"{self.base_url}/item/{story_id}.json"
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆå„ã‚¹ãƒˆãƒ¼ãƒªãƒ¼å–å¾—å‰ã«ï¼‰
                    self.rate_limiter.wait_if_needed()
                    
                    story_response = requests.get(story_url, timeout=5)
                    
                    if story_response.status_code == 200:
                        story_data = story_response.json()
                        
                        # ã‚¹ãƒˆãƒ¼ãƒªãƒ¼æƒ…å ±ã‚’æ•´å½¢
                        stories.append({
                            'story_id': story_id,
                            'title': story_data.get('title', 'No Title'),
                            'url': story_data.get('url', f"https://news.ycombinator.com/item?id={story_id}"),
                            'score': story_data.get('score', 0),
                            'by': story_data.get('by', 'Unknown'),
                            'time': story_data.get('time', 0),
                            'comments': story_data.get('descendants', 0),
                            'type': story_data.get('type', 'story'),
                            'story_type': story_type
                        })
                        
                except Exception as e:
                    logger.warning(f"ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ {story_id} å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                    continue
            
            # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
            stories.sort(key=lambda x: x.get('score', 0), reverse=True)
            
            # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­å®š
            for i, story in enumerate(stories, 1):
                story['rank'] = i
            
            logger.info(f"âœ… Hacker News: {len(stories)}ä»¶ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’å–å¾—ã—ã€ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆã—ã¾ã—ãŸ")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self.db.save_hackernews_trends_to_cache(stories, story_type)
            
            return {
                'success': True,
                'data': stories,
                'status': 'api_fetched',
                'source': 'Hacker News API',
                'story_type': story_type,
                'total_count': len(stories)
            }
            
        except Exception as e:
            logger.error(f"âŒ Hacker News API ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {
                'error': f'Hacker Newsã‚¹ãƒˆãƒ¼ãƒªãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}',
                'success': False
            }




