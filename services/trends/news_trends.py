import os
import requests
from datetime import datetime, timedelta
from database_config import TrendsCache
from utils.logger_config import get_logger
from utils.rate_limiter import get_rate_limiter

# ãƒ­ã‚¬ãƒ¼ã®åˆæœŸåŒ–
logger = get_logger(__name__)

class NewsTrendsManager:
    """NewsAPIã‚’ä½¿ç”¨ã—ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ãƒ»ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.api_key = os.getenv('NEWS_API_KEY')
        self.db = TrendsCache()
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™: News APIã¯100 requests/æ—¥ï¼ˆä¿å®ˆçš„ã«10ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/åˆ†ã«è¨­å®šï¼‰
        self.rate_limiter = get_rate_limiter('news', max_requests=10, window_seconds=60)
        
        if not self.api_key:
            logger.warning("Warning: NEWS_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        logger.debug(f"News APIèªè¨¼æƒ…å ±ç¢ºèª:")
        logger.debug(f"  API Key: {self.api_key[:10]}..." if self.api_key else "  API Key: æœªè¨­å®š")
        
        # NewsAPIæ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¢ãƒ¼ãƒ‰ã§ã¯ç„¡åŠ¹åŒ–ï¼‰
        # if self.api_key:
        #     self._test_connection()
    
    def _test_connection(self):
        """NewsAPIæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        try:
            # ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            test_url = f"https://newsapi.org/v2/top-headlines?country=jp&apiKey={self.api_key}"
            response = requests.get(test_url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                logger.info(f"News APIæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ: {data.get('totalResults', 0)}ä»¶ã®è¨˜äº‹")
                logger.debug(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹è©³ç´°: {data}")
            else:
                logger.warning(f"News APIæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {response.status_code}")
                logger.warning(f"ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.text}")
                
        except Exception as e:
            logger.error(f"News APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    
    def get_trends(self, country='jp', category='general', page_size=25, force_refresh=False):
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ã¿å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã—ï¼‰"""
        try:
            logger.debug(f"ğŸ” News: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ (country: {country}, category: {category})")
            
            cached_data = None
            if force_refresh:
                logger.info(f"ğŸ”„ News: force_refreshæŒ‡å®šã®ãŸã‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ (country: {country}, category: {category})")
            else:
                cached_data = self.get_from_cache(country, category)
                logger.debug(f"ğŸ” News: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿å–å¾—çµæœ: {type(cached_data)}, é•·ã•: {len(cached_data) if cached_data else 0}")
            
            if cached_data:
                logger.info(f"âœ… News: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ ({len(cached_data)}ä»¶)")
                return {
                    'data': cached_data,
                    'status': 'cached',
                    'country': country.upper(),
                    'category': category
                }
            # force_refresh=Falseã®å ´åˆã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„å ´åˆã§ã‚‚å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã•ãªã„
            if not force_refresh:
                logger.warning(f"âš ï¸ News: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ãŒã€force_refresh=falseã®ãŸã‚å¤–éƒ¨APIã¯å‘¼ã³å‡ºã—ã¾ã›ã‚“ (country: {country}, category: {category})")
                return {
                    'data': [],
                    'status': 'cache_not_found',
                    'country': country.upper(),
                    'category': category,
                    'success': False,
                    'error': 'ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“'
                }
            # force_refresh=trueã®å ´åˆã®ã¿å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã™
            logger.warning(f"âš ï¸ News: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœªä½¿ç”¨ã®ãŸã‚å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã—ã¾ã™")
            trends_data = self._get_news_trends(country, category, page_size)
            if trends_data:
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                self.save_to_cache(trends_data, country, category)
                logger.info(f"âœ… News: å¤–éƒ¨APIã‹ã‚‰{len(trends_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸ")
                return {
                    'data': trends_data,
                    'status': 'api_fetched',
                    'country': country.upper(),
                    'category': category,
                    'source': 'News API'
                }
            else:
                logger.error(f"âŒ News: å¤–éƒ¨APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return {
                    'data': [],
                    'status': 'api_error',
                    'country': country.upper(),
                    'category': category
                }
                
        except Exception as e:
            logger.error(f"ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {'error': f'ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}'}
    
    def _get_news_trends(self, country='jp', category='general', page_size=25):
        """NewsAPIã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        if not self.api_key:
            logger.warning("News APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        
        try:
            logger.info(f"News APIå‘¼ã³å‡ºã—é–‹å§‹ (å›½: {country}, ã‚«ãƒ†ã‚´ãƒª: {category})")
            
            # è¤‡æ•°ã®æ–¹æ³•ã§è¨˜äº‹ã‚’å–å¾—ã—ã‚ˆã†ã¨ã™ã‚‹
            trends = []
            
            # 1. ã‚«ãƒ†ã‚´ãƒªä»˜ãtop-headlinesï¼ˆè¤‡æ•°ã®ã‚«ãƒ†ã‚´ãƒªã‚’è©¦è¡Œï¼‰
            logger.debug("1. ã‚«ãƒ†ã‚´ãƒªä»˜ãtop-headlinesã‚’è©¦è¡Œ...")
            categories_to_try = ['general', 'business', 'technology', 'entertainment', 'sports']
            for cat in categories_to_try:
                logger.debug(f"   ã‚«ãƒ†ã‚´ãƒª '{cat}' ã‚’è©¦è¡Œ...")
                trends = self._get_news_trends_with_category(country, cat, page_size)
                if trends and len(trends) > 0:
                    logger.info(f"   ã‚«ãƒ†ã‚´ãƒª '{cat}' ã§è¨˜äº‹ã‚’å–å¾—ã—ã¾ã—ãŸï¼")
                    break
            
            # 2. ã‚«ãƒ†ã‚´ãƒªãªã—top-headlines
            if not trends or len(trends) == 0:
                logger.debug("2. ã‚«ãƒ†ã‚´ãƒªãªã—top-headlinesã‚’è©¦è¡Œ...")
                trends = self._get_news_trends_without_category(country, page_size)
            
            # 3. ç•°ãªã‚‹å›½ã§è©¦è¡Œï¼ˆJPãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            # JPãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€JPã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—ã™ã‚‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ä»–ã®å›½ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ãªã„ï¼‰
            if country.lower() != 'jp' and (not trends or len(trends) == 0):
                logger.debug("3. ç•°ãªã‚‹å›½ã§è©¦è¡Œ...")
                countries_to_try = ['us', 'gb', 'ca', 'au']
                for c in countries_to_try:
                    logger.debug(f"   å›½ '{c}' ã‚’è©¦è¡Œ...")
                    trends = self._get_news_trends_without_category(c, page_size)
                    if trends and len(trends) > 0:
                        logger.info(f"   å›½ '{c}' ã§è¨˜äº‹ã‚’å–å¾—ã—ã¾ã—ãŸï¼")
                        break
            
            # 4. everythingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§æ¤œç´¢ï¼ˆJPãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            if country.lower() != 'jp' and (not trends or len(trends) == 0):
                logger.debug("4. everythingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§æ¤œç´¢ã‚’è©¦è¡Œ...")
                trends = self._get_news_trends_everything(country, page_size)
            
            # 5. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€å¾Œã®æ‰‹æ®µã€JPãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            # JPãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãªã„ï¼ˆç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ï¼‰
            if country.lower() != 'jp' and (not trends or len(trends) == 0):
                logger.warning("5. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ...")
                trends = self._get_sample_news_data()
            
            return trends
            
        except Exception as e:
            logger.error(f"News API ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            import traceback
            traceback.print_exc()
            return None
    
    def _get_news_trends_with_category(self, country='jp', category='general', page_size=25):
        """ã‚«ãƒ†ã‚´ãƒªä»˜ãã§NewsAPIã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            url = "https://newsapi.org/v2/top-headlines"
            params = {
                'country': country,
                'category': category,
                'pageSize': page_size,
                'apiKey': self.api_key
            }
            
            logger.debug(f"ã‚«ãƒ†ã‚´ãƒªä»˜ããƒªã‚¯ã‚¨ã‚¹ãƒˆ: {params}")
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯
            self.rate_limiter.wait_if_needed()
            
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code != 200:
                logger.error(f"News API ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                return None
            
            data = response.json()
            logger.debug(f"News API ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {data}")
            
            if data.get('status') != 'ok':
                logger.error(f"News API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼: {data.get('message', 'Unknown error')}")
                return None
            
            articles = data.get('articles', [])
            logger.info(f"ã‚«ãƒ†ã‚´ãƒª '{category}' ã§å–å¾—è¨˜äº‹æ•°: {len(articles)}ä»¶")
            
            if len(articles) == 0:
                return []
            
            trends = []
            for i, article in enumerate(articles, 1):
                # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆé †ä½ãƒ™ãƒ¼ã‚¹ï¼‰
                score = 100 * (1 - (i - 1) / (len(articles) - 1)) if len(articles) > 1 else 100
                
                trends.append({
                    'rank': i,
                    'title': article.get('title', 'No Title'),
                    'description': article.get('description', ''),
                    'source': article.get('source', {}).get('name', 'Unknown'),
                    'url': article.get('url', ''),
                    'image_url': article.get('urlToImage', ''),
                    'published_at': article.get('publishedAt', ''),
                    'score': round(score, 1),
                    'category': category
                })
            
            return trends
            
        except Exception as e:
            logger.error(f"ã‚«ãƒ†ã‚´ãƒªä»˜ãNews API ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return []
    
    def _get_news_trends_without_category(self, country='jp', page_size=25):
        """ã‚«ãƒ†ã‚´ãƒªãªã—ã§NewsAPIã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            url = "https://newsapi.org/v2/top-headlines"
            params = {
                'country': country,
                'pageSize': page_size,
                'apiKey': self.api_key
            }
            
            logger.debug(f"ã‚«ãƒ†ã‚´ãƒªãªã—ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {params}")
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯
            self.rate_limiter.wait_if_needed()
            
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code != 200:
                logger.error(f"News API ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                return None
            
            data = response.json()
            logger.debug(f"News API ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {data}")
            
            if data.get('status') != 'ok':
                logger.error(f"News API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼: {data.get('message', 'Unknown error')}")
                return None
            
            articles = data.get('articles', [])
            logger.info(f"ã‚«ãƒ†ã‚´ãƒªãªã—ã§å–å¾—è¨˜äº‹æ•°: {len(articles)}ä»¶")
            
            if len(articles) == 0:
                logger.warning("ã‚«ãƒ†ã‚´ãƒªãªã—ã§ã‚‚è¨˜äº‹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return []
            
            trends = []
            for i, article in enumerate(articles, 1):
                # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆé †ä½ãƒ™ãƒ¼ã‚¹ï¼‰
                score = 100 * (1 - (i - 1) / (len(articles) - 1)) if len(articles) > 1 else 100
                
                trends.append({
                    'rank': i,
                    'title': article.get('title', 'No Title'),
                    'description': article.get('description', ''),
                    'source': article.get('source', {}).get('name', 'Unknown'),
                    'url': article.get('url', ''),
                    'image_url': article.get('urlToImage', ''),
                    'published_at': article.get('publishedAt', ''),
                    'score': round(score, 1),
                    'category': 'general'
                })
            
            logger.info(f"ã‚«ãƒ†ã‚´ãƒªãªã—ã§å‡¦ç†å®Œäº†: {len(trends)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿")
            return trends
            
        except Exception as e:
            logger.error(f"ã‚«ãƒ†ã‚´ãƒªãªã—News API ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return []
    
    def _get_news_trends_everything(self, country='jp', page_size=25):
        """everythingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§NewsAPIã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            url = "https://newsapi.org/v2/everything"
            
            # å›½åˆ¥ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’è¨­å®š
            country_queries = {
                'jp': 'japan OR æ—¥æœ¬ OR æ±äº¬ OR å¤§é˜ª',
                'us': 'united states OR USA OR America',
                'gb': 'united kingdom OR UK OR Britain'
            }
            
            query = country_queries.get(country.lower(), 'news')
            
            params = {
                'q': query,
                'language': 'en' if country.lower() != 'jp' else 'en,ja',
                'sortBy': 'publishedAt',
                'pageSize': page_size,
                'apiKey': self.api_key
            }
            
            logger.debug(f"everythingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {params}")
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯
            self.rate_limiter.wait_if_needed()
            
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code != 200:
                logger.error(f"News API everything ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                return []
            
            data = response.json()
            logger.debug(f"News API everything ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {data}")
            
            if data.get('status') != 'ok':
                logger.error(f"News API everything ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼: {data.get('message', 'Unknown error')}")
                return []
            
            articles = data.get('articles', [])
            logger.info(f"everythingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§å–å¾—è¨˜äº‹æ•°: {len(articles)}ä»¶")
            
            if len(articles) == 0:
                logger.warning("everythingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ã‚‚è¨˜äº‹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return []
            
            trends = []
            for i, article in enumerate(articles, 1):
                # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆé †ä½ãƒ™ãƒ¼ã‚¹ï¼‰
                score = 100 * (1 - (i - 1) / (len(articles) - 1)) if len(articles) > 1 else 100
                
                trends.append({
                    'rank': i,
                    'title': article.get('title', 'No Title'),
                    'description': article.get('description', ''),
                    'source': article.get('source', {}).get('name', 'Unknown'),
                    'url': article.get('url', ''),
                    'image_url': article.get('urlToImage', ''),
                    'published_at': article.get('publishedAt', ''),
                    'score': round(score, 1),
                    'category': 'general'
                })
            
            logger.info(f"everythingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§å‡¦ç†å®Œäº†: {len(trends)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿")
            return trends
            
        except Exception as e:
            logger.error(f"everythingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆNews API ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return []
    
    def _get_sample_news_data(self):
        """ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
        logger.warning("ã‚µãƒ³ãƒ—ãƒ«ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™")
        
        sample_news = [
            {
                'rank': 1,
                'title': 'AIæŠ€è¡“ã®æœ€æ–°å‹•å‘ã¨å°†æ¥å±•æœ›',
                'description': 'äººå·¥çŸ¥èƒ½æŠ€è¡“ã®æœ€æ–°ã®é€²æ­©ã¨ã€ä»Šå¾Œã®ç™ºå±•æ–¹å‘æ€§ã«ã¤ã„ã¦',
                'source': 'Tech News Japan',
                'url': 'https://example.com/ai-news-1',
                'image_url': '',
                'published_at': '2025-08-28T10:00:00Z',
                'score': 100.0,
                'category': 'technology'
            },
            {
                'rank': 2,
                'title': 'æŒç¶šå¯èƒ½ãªã‚¨ãƒãƒ«ã‚®ãƒ¼æ”¿ç­–ã®æ¨é€²',
                'description': 'å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸­å¿ƒã¨ã—ãŸç’°å¢ƒé…æ…®å‹ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼æˆ¦ç•¥',
                'source': 'Environment Daily',
                'url': 'https://example.com/energy-news-1',
                'image_url': '',
                'published_at': '2025-08-28T09:30:00Z',
                'score': 95.0,
                'category': 'environment'
            },
            {
                'rank': 3,
                'title': 'ã‚°ãƒ­ãƒ¼ãƒãƒ«çµŒæ¸ˆã®æ–°ãŸãªæ½®æµ',
                'description': 'ä¸–ç•ŒçµŒæ¸ˆã«ãŠã‘ã‚‹æœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã¨å¸‚å ´å‹•å‘ã®åˆ†æ',
                'source': 'Global Finance',
                'url': 'https://example.com/economy-news-1',
                'image_url': '',
                'published_at': '2025-08-28T09:00:00Z',
                'score': 90.0,
                'category': 'business'
            },
            {
                'rank': 4,
                'title': 'å¥åº·ã¨ã‚¦ã‚§ãƒ«ãƒã‚¹ã®æœ€æ–°ç ”ç©¶',
                'description': 'ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ãå¥åº·ç¶­æŒã¨ç”Ÿæ´»ç¿’æ…£æ”¹å–„ã®æ–¹æ³•',
                'source': 'Health Science',
                'url': 'https://example.com/health-news-1',
                'image_url': '',
                'published_at': '2025-08-28T08:30:00Z',
                'score': 85.0,
                'category': 'health'
            },
            {
                'rank': 5,
                'title': 'ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©ã®åŠ é€Ÿ',
                'description': 'ä¼æ¥­ã®ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–æ¨é€²ã¨DXæˆ¦ç•¥ã®æœ€æ–°äº‹ä¾‹',
                'source': 'Digital Times',
                'url': 'https://example.com/digital-news-1',
                'image_url': '',
                'published_at': '2025-08-28T08:00:00Z',
                'score': 80.0,
                'category': 'technology'
            }
        ]
        
        logger.info(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(sample_news)}ä»¶")
        return sample_news
    
    def get_from_cache(self, country, category):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            return self.db.get_news_trends_from_cache(country, category)
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return None
    
    def save_to_cache(self, data, country, category):
        """ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        try:
            self.db.save_news_trends_to_cache(data, country, category)
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    
    def is_cache_valid(self, country, category):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            return self.db.is_news_cache_valid(country, category)
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return False 