import os
import requests
from datetime import datetime, timedelta
from database_config import TrendsCache
from utils.logger_config import get_logger
from utils.rate_limiter import get_rate_limiter

# ãƒ­ã‚¬ãƒ¼ã®åˆæœŸåŒ–
logger = get_logger(__name__)

class PodcastTrendsManager:
    """Listen Notes APIã‚’ä½¿ç”¨ã—ã¦ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ãƒ»ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.api_key = os.getenv('LISTEN_API_KEY')
        self.base_url = "https://listen-api.listennotes.com/api/v2"
        self.db = TrendsCache()
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™: Listen Notes APIã¯300 requests/æœˆï¼ˆä¿å®ˆçš„ã«10ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/åˆ†ã«è¨­å®šï¼‰
        self.rate_limiter = get_rate_limiter('podcast', max_requests=10, window_seconds=60)
        
        if not self.api_key:
            logger.warning("Warning: LISTEN_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        logger.debug(f"Listen Notes APIèªè¨¼æƒ…å ±ç¢ºèª:")
        logger.debug(f"  API Key: {self.api_key[:10]}..." if self.api_key else "  API Key: æœªè¨­å®š")
        
        # Listen Notes APIæ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¢ãƒ¼ãƒ‰ã§ã¯ç„¡åŠ¹åŒ–ï¼‰
        # if self.api_key:
        #     self._test_connection()
    
    def _test_connection(self):
        """Listen Notes APIæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        try:
            # ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆgenresã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰
            test_url = f"{self.base_url}/genres"
            headers = {'X-ListenAPI-Key': self.api_key}
            
            response = requests.get(test_url, headers=headers, timeout=30)
            
            if response.status_code == 200:
                logger.info("Listen Notes APIæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
            else:
                logger.warning(f"Listen Notes APIæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {response.status_code}")
                
        except Exception as e:
            logger.error(f"Listen Notes APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    
    def get_trends(self, trend_type='best_podcasts', genre_id=None, region='jp', page_size=25, force_refresh=False):
        """ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ã¿å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã—ï¼‰"""
        try:
            logger.debug(f"ğŸ” Podcast: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ (trend_type: {trend_type}, region: {region})")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            cache_key = f"{trend_type}_{genre_id or 'all'}_{region}"
            cached_data = None
            if force_refresh:
                logger.info(f"ğŸ”„ Podcast: force_refreshæŒ‡å®šã®ãŸã‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ (cache_key: {cache_key})")
            else:
                cached_data = self.get_from_cache(cache_key, region)
                if cached_data:
                    logger.info(f"âœ… Podcast: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ ({len(cached_data)}ä»¶, cache_key: {cache_key})")
                else:
                    logger.debug(f"ğŸ” Podcast: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ (cache_key: {cache_key})")
            
            if cached_data:
                # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰ã€åŒã˜å ´åˆã¯ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
                cached_data.sort(key=lambda x: (x.get('total_episodes', 0), x.get('score', 0)), reverse=True)
                
                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å†è¨­å®š
                for i, item in enumerate(cached_data, 1):
                    item['rank'] = i
                    # ã‚¹ã‚³ã‚¢ã‚‚å†è¨ˆç®—
                    score = 100 * (1 - (i - 1) / (len(cached_data) - 1)) if len(cached_data) > 1 else 100
                    item['score'] = round(score, 1)
                
                logger.info(f"âœ… Podcast: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°ã§ã‚½ãƒ¼ãƒˆã—ã¾ã—ãŸ ({len(cached_data)}ä»¶)")
                return {
                    'data': cached_data,
                    'status': 'cached',
                    'trend_type': trend_type,
                    'genre_id': genre_id,
                    'region': region.upper()
                }
            logger.warning(f"âš ï¸ Podcast: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœªä½¿ç”¨ã®ãŸã‚å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã—ã¾ã™")
            if trend_type == 'best_podcasts':
                trends_data = self._get_best_podcasts(genre_id, page_size, region)
            elif trend_type == 'trending_searches':
                trends_data = self._get_trending_searches(region, page_size)
            else:
                logger.error(f"âŒ æœªå¯¾å¿œã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¿ã‚¤ãƒ—: {trend_type}")
                return {
                    'data': [],
                    'status': 'unsupported_type',
                    'trend_type': trend_type,
                    'genre_id': genre_id,
                    'region': region.upper()
                }
            
            if trends_data:
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                self.save_to_cache(trends_data, cache_key, region)
                logger.info(f"âœ… Podcast: å¤–éƒ¨APIã‹ã‚‰{len(trends_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸ")
                return {
                    'data': trends_data,
                    'status': 'api_fetched',
                    'trend_type': trend_type,
                    'genre_id': genre_id,
                    'region': region.upper(),
                    'source': 'Listen Notes API'
                }
            else:
                logger.error(f"âŒ Podcast: å¤–éƒ¨APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return {
                    'data': [],
                    'status': 'api_error',
                    'trend_type': trend_type,
                    'genre_id': genre_id,
                    'region': region.upper()
                }
                
        except Exception as e:
            logger.error(f"ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {'error': f'ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆãƒˆãƒ¬ãƒ³ãƒ‰ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}'}
    
    def _get_best_podcasts(self, genre_id=None, page_size=25, region='jp'):
        """ãƒ™ã‚¹ãƒˆãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã‚’å–å¾—"""
        try:
            url = f"{self.base_url}/best_podcasts"
            headers = {'X-ListenAPI-Key': self.api_key}
            
            params = {
                'page_size': page_size,
                'region': region
            }
            
            if genre_id:
                params['genre_id'] = genre_id
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯
            self.rate_limiter.wait_if_needed()
            
            response = requests.get(url, headers=headers, params=params, timeout=30)
            
            if response.status_code != 200:
                logger.error(f"Listen Notes API ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                return None
            
            data = response.json()
            podcasts = data.get('podcasts', [])
            
            if len(podcasts) == 0:
                return []
            
            trends = []
            for podcast in podcasts:
                # podcast_idã‚’å–å¾—ï¼ˆidãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¾ãŸã¯listennotes_urlã‹ã‚‰æŠ½å‡ºï¼‰
                podcast_id = podcast.get('id', '')
                if not podcast_id and podcast.get('listennotes_url'):
                    # listennotes_urlã‹ã‚‰IDã‚’æŠ½å‡º: https://www.listennotes.com/c/{id}/
                    url_parts = podcast.get('listennotes_url', '').split('/')
                    podcast_id = url_parts[-2] if len(url_parts) > 1 else ''
                
                trends.append({
                    'id': podcast_id,  # podcast_idã¨ã—ã¦ä½¿ç”¨
                    'podcast_id': podcast_id,  # æ˜ç¤ºçš„ã«podcast_idã‚‚è¨­å®š
                    'title': podcast.get('title', 'No Title'),
                    'description': podcast.get('description', ''),
                    'publisher': podcast.get('publisher', 'Unknown'),
                    'url': podcast.get('website', ''),
                    'image_url': podcast.get('image', ''),
                    'language': podcast.get('language', 'en'),
                    'country': podcast.get('country', 'Unknown'),
                    'total_episodes': podcast.get('total_episodes', 0),
                    'listennotes_url': podcast.get('listennotes_url', ''),
                    'explicit_content': podcast.get('explicit_content', False),
                    'latest_episode_pub_date': podcast.get('latest_episode_pub_date', ''),
                    'earliest_episode_pub_date': podcast.get('earliest_episode_pub_date', ''),
                    'trend_type': 'best_podcasts'
                })
            
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰ã€åŒã˜å ´åˆã¯ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
            trends.sort(key=lambda x: (x.get('total_episodes', 0), x.get('score', 0)), reverse=True)
            
            # ã‚¹ã‚³ã‚¢è¨ˆç®—ã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­å®š
            for i, trend in enumerate(trends, 1):
                # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆé †ä½ãƒ™ãƒ¼ã‚¹ï¼‰
                score = 100 * (1 - (i - 1) / (len(trends) - 1)) if len(trends) > 1 else 100
                trend['score'] = round(score, 1)
                trend['rank'] = i
            
            return trends
            
        except Exception as e:
            logger.error(f"ãƒ™ã‚¹ãƒˆãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return None
    
    def _get_trending_searches(self, region='jp', page_size=25):
        """ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—"""
        try:
            url = f"{self.base_url}/trending_searches"
            headers = {'X-ListenAPI-Key': self.api_key}
            
            params = {
                'region': region,
                'size': page_size
            }
            
            logger.debug(f"ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {params}")
            response = requests.get(url, headers=headers, params=params, timeout=30)
            
            if response.status_code != 200:
                logger.error(f"Listen Notes API ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                return None
            
            data = response.json()
            logger.debug(f"Listen Notes API ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {data}")
            
            searches = data.get('terms', [])
            logger.info(f"ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢å–å¾—æ•°: {len(searches)}ä»¶")
            
            if len(searches) == 0:
                return []
            
            trends = []
            for i, search in enumerate(searches, 1):
                # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆé †ä½ãƒ™ãƒ¼ã‚¹ï¼‰
                score = 100 * (1 - (i - 1) / (len(searches) - 1)) if len(searches) > 1 else 100
                
                trends.append({
                    'rank': i,
                    'title': search.get('term', 'No Term'),
                    'description': f"ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ #{i}",
                    'publisher': 'Listen Notes',
                    'url': f"https://www.listennotes.com/search/?q={search.get('term', '')}",
                    'image_url': '',
                    'language': 'en',
                    'country': region.upper(),
                    'score': round(score, 1),
                    'trend_type': 'trending_searches'
                })
            
            logger.info(f"ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢å‡¦ç†å®Œäº†: {len(trends)}ä»¶")
            return trends
            
        except Exception as e:
            logger.error(f"ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return []
    
    def get_genres(self):
        """åˆ©ç”¨å¯èƒ½ãªã‚¸ãƒ£ãƒ³ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        try:
            url = f"{self.base_url}/genres"
            headers = {'X-ListenAPI-Key': self.api_key}
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯
            self.rate_limiter.wait_if_needed()
            
            response = requests.get(url, headers=headers, timeout=30)
            
            if response.status_code != 200:
                logger.error(f"Listen Notes API ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                return []
            
            data = response.json()
            genres = data.get('genres', [])
            
            logger.info(f"åˆ©ç”¨å¯èƒ½ãªã‚¸ãƒ£ãƒ³ãƒ«æ•°: {len(genres)}ä»¶")
            return genres
            
        except Exception as e:
            logger.error(f"ã‚¸ãƒ£ãƒ³ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return []
    
    def get_regions(self):
        """åˆ©ç”¨å¯èƒ½ãªå›½ãƒ»åœ°åŸŸã‚³ãƒ¼ãƒ‰ä¸€è¦§ã‚’å–å¾—"""
        try:
            url = f"{self.base_url}/regions"
            headers = {'X-ListenAPI-Key': self.api_key}
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯
            self.rate_limiter.wait_if_needed()
            
            response = requests.get(url, headers=headers, timeout=30)
            
            if response.status_code != 200:
                logger.error(f"Listen Notes API ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
                return []
            
            data = response.json()
            regions = data.get('regions', [])
            
            logger.info(f"åˆ©ç”¨å¯èƒ½ãªå›½ãƒ»åœ°åŸŸæ•°: {len(regions)}ä»¶")
            return regions
            
        except Exception as e:
            logger.error(f"å›½ãƒ»åœ°åŸŸå–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return []
    
    def get_from_cache(self, cache_key, region):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            return self.db.get_podcast_trends_from_cache('podcast_trends', region)
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return None
    
    def save_to_cache(self, data, cache_key, region):
        """ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        try:
            self.db.save_podcast_trends_to_cache(data, 'podcast_trends', region)
            # cache_statusãƒ†ãƒ¼ãƒ–ãƒ«ã‚‚æ›´æ–°
            self._update_cache_status('podcast_trends', len(data))
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    
    def _update_cache_status(self, cache_key, data_count):
        """cache_statusãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°"""
        try:
            from datetime import datetime
            import pytz
            # æ—¥æœ¬æ™‚é–“ã§ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—
            jst = pytz.timezone('Asia/Tokyo')
            now = datetime.now(jst)
            
            with self.db.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        INSERT INTO cache_status (cache_key, last_updated, data_count)
                        VALUES (%s, %s, %s)
                        ON CONFLICT (cache_key) DO UPDATE SET
                            last_updated = EXCLUDED.last_updated,
                            data_count = EXCLUDED.data_count
                    """, (cache_key, now, data_count))
                    conn.commit()
        except Exception as e:
            logger.error(f"cache_statusæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    
    def is_cache_valid(self, cache_key, region):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            return self.db.is_podcast_cache_valid(cache_key, region)
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return False
    
    def _should_refresh_cache(self, trend_type, region):
        """ä»Šæ—¥æ—¢ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã—ãŸã‹ãƒã‚§ãƒƒã‚¯ï¼ˆæœ5æ™‚ã‹ã‚‰å¤œ12æ™‚ã¾ã§ï¼‰"""
        try:
            from datetime import datetime
            import pytz
            # æ—¥æœ¬æ™‚é–“ã§ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—
            jst = pytz.timezone('Asia/Tokyo')
            now = datetime.now(jst)
            today = now.date()
            current_hour = now.hour
            
            # æ™‚é–“åˆ¶é™ï¼š5æ™‚ã‹ã‚‰24æ™‚ã¾ã§
            if not (5 <= current_hour < 24):
                logger.info(f"âš ï¸ æ™‚é–“å¤–ã§ã™ï¼ˆ{current_hour}æ™‚ï¼‰ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                return False
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æœ€å¾Œã®æ›´æ–°æ—¥æ™‚ã‚’å–å¾—
            with self.db.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        SELECT last_updated 
                        FROM cache_status 
                        WHERE cache_key = %s
                    """, ('podcast_trends',))
                    
                    result = cursor.fetchone()
                    if result and result[0]:
                        last_refresh = result[0].date()
                        return last_refresh < today
                    return True  # åˆå›ã¯æ›´æ–°ã™ã‚‹
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°æ—¥æ™‚ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return True 