import os
import requests
from datetime import datetime, timedelta
from dotenv import load_dotenv
from database_config import TrendsCache
from utils.logger_config import get_logger
from utils.rate_limiter import get_rate_limiter

# ç’°å¢ƒå¤‰æ•°ã‚’æ˜ç¤ºçš„ã«èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚¬ãƒ¼ã®åˆæœŸåŒ–
logger = get_logger(__name__)

class RakutenTrendsManager:
    """æ¥½å¤©ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ãƒ»ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.db = TrendsCache()
        self.rakuten_app_id = os.getenv('RAKUTEN_APP_ID')
        self.rakuten_affiliate_id = os.getenv('RAKUTEN_AFFILIATE_ID')
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™: æ¥½å¤©APIã¯1ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ç§’
        self.rate_limiter = get_rate_limiter('rakuten', max_requests=10, window_seconds=60)
        
        logger.info(f"Rakuten Trends ManageråˆæœŸåŒ–:")
        logger.info(f"  App ID: {'è¨­å®šæ¸ˆã¿' if self.rakuten_app_id else 'æœªè¨­å®š'}")
        logger.info(f"  Affiliate ID: {'è¨­å®šæ¸ˆã¿' if self.rakuten_affiliate_id else 'æœªè¨­å®š'}")
        
        # ãƒ‡ãƒãƒƒã‚°: ç’°å¢ƒå¤‰æ•°ã®å€¤ã‚’ç¢ºèª
        logger.debug(f"  App IDå€¤: {self.rakuten_app_id}")
        logger.debug(f"  Affiliate IDå€¤: {self.rakuten_affiliate_id}")
    
    def get_trends(self, genre_id=None, limit=25, force_refresh=False):
        """æ¥½å¤©ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ï¼ˆget_popular_itemsã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼‰"""
        return self.get_popular_items(genre_id, limit, force_refresh)
    
    def get_popular_items(self, genre_id=None, limit=25, force_refresh=False):
        """æ¥½å¤©äººæ°—å•†å“ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ã¿å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã—ï¼‰"""
        try:
            cache_scope = genre_id or 'all'
            cached_data = None
            
            if force_refresh:
                logger.info(f"ğŸ”„ æ¥½å¤©: force_refreshæŒ‡å®šã®ãŸã‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ (scope: {cache_scope})")
            else:
                logger.debug(f"ğŸ” æ¥½å¤©: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ (genre_id: {genre_id})")
                cached_data = self.get_from_cache(cache_scope)
                logger.debug(f"ğŸ” æ¥½å¤©: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿å–å¾—çµæœ: {type(cached_data)}, é•·ã•: {len(cached_data) if cached_data else 0}")
            
            if cached_data:
                # sales_countã‚’æ•°å€¤ã«å¤‰æ›ï¼ˆ'N/A'ã®å ´åˆã¯0ï¼‰
                for item in cached_data:
                    sales_count = item.get('sales_count', 'N/A')
                    if isinstance(sales_count, str) and sales_count != 'N/A':
                        try:
                            item['sales_count'] = int(sales_count)
                        except:
                            item['sales_count'] = 0
                    elif sales_count == 'N/A' or sales_count is None:
                        item['sales_count'] = 0
                
                # å£²ä¸Šæ•°ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰ã€åŒã˜å ´åˆã¯ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã§ã‚½ãƒ¼ãƒˆ
                cached_data.sort(key=lambda x: (x.get('sales_count', 0), x.get('review_count', 0)), reverse=True)
                
                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å†è¨­å®š
                for i, item in enumerate(cached_data, 1):
                    item['rank'] = i
                
                logger.info(f"âœ… æ¥½å¤©: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã€å£²ä¸Šæ•°ã§ã‚½ãƒ¼ãƒˆã—ã¾ã—ãŸ ({len(cached_data)}ä»¶)")
                cache_info = self._get_cache_info(cache_scope)
                return {
                    'data': cached_data,
                    'status': 'cached',
                    'genre_id': genre_id,
                    'cache_info': cache_info
                }
            
            # force_refresh=Falseã®å ´åˆã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„å ´åˆã§ã‚‚å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã•ãªã„
            if not force_refresh:
                logger.warning(f"âš ï¸ æ¥½å¤©: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ãŒã€force_refresh=falseã®ãŸã‚å¤–éƒ¨APIã¯å‘¼ã³å‡ºã—ã¾ã›ã‚“ (genre_id: {genre_id})")
                return {
                    'data': [],
                    'status': 'cache_not_found',
                    'genre_id': genre_id,
                    'success': False,
                    'error': 'ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“'
                }
            # force_refresh=trueã®å ´åˆã®ã¿å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã™
            logger.warning(f"âš ï¸ æ¥½å¤©: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœªä½¿ç”¨ã®ãŸã‚å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã—ã¾ã™")
            api_result = self._get_rakuten_ranking(genre_id, limit)
            if api_result and api_result.get('data'):
                trends_data = api_result['data']
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                self.save_to_cache(trends_data, cache_scope)
                self._update_refresh_time(cache_scope)
                logger.info(f"âœ… æ¥½å¤©: å¤–éƒ¨APIã‹ã‚‰{len(trends_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸ")
                return {
                    'data': trends_data,
                    'status': 'api_fetched',
                    'genre_id': genre_id,
                    'source': 'æ¥½å¤©å•†å“ãƒ©ãƒ³ã‚­ãƒ³ã‚°API'
                }
            else:
                logger.error(f"âŒ æ¥½å¤©: å¤–éƒ¨APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return {
                    'data': [],
                    'status': 'api_error',
                    'genre_id': genre_id
                }
        
        except Exception as e:
            return {'error': f'æ¥½å¤©ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}'}
    
    def _get_rakuten_ranking(self, genre_id=None, limit=25):
        """æ¥½å¤©å•†å“ãƒ©ãƒ³ã‚­ãƒ³ã‚°APIã‚’ä½¿ç”¨"""
        try:
            url = "https://app.rakuten.co.jp/services/api/IchibaItem/Ranking/20170628"
            params = {
                'applicationId': self.rakuten_app_id,
                'format': 'json',
                'hits': limit,
                'sort': 'standard'  # æ¥½å¤©ã®æ¨™æº–çš„ãªä¸¦ã³é †
            }
            
            if self.rakuten_affiliate_id:
                params['affiliateId'] = self.rakuten_affiliate_id
            
            if genre_id:
                params['genreId'] = genre_id
            
            logger.debug(f"æ¥½å¤©ãƒ©ãƒ³ã‚­ãƒ³ã‚°APIãƒªã‚¯ã‚¨ã‚¹ãƒˆURL: {url}")
            logger.debug(f"æ¥½å¤©ãƒ©ãƒ³ã‚­ãƒ³ã‚°APIãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {params}")
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯
            self.rate_limiter.wait_if_needed()
            
            response = requests.get(url, params=params, timeout=10)
            logger.debug(f"æ¥½å¤©ãƒ©ãƒ³ã‚­ãƒ³ã‚°APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                items = data.get('Items', [])
                
                # ãƒ‡ãƒãƒƒã‚°: æœ€åˆã®ã‚¢ã‚¤ãƒ†ãƒ ã®å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç¢ºèª
                if items:
                    first_item = items[0].get('Item', {})
                    logger.debug(f"æ¥½å¤©APIã‚¢ã‚¤ãƒ†ãƒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {list(first_item.keys())}")
                    logger.debug(f"æ¥½å¤©APIã‚¢ã‚¤ãƒ†ãƒ ã‚µãƒ³ãƒ—ãƒ«: {first_item}")
                
                trends_data = []
                for item in items:
                    item_info = item.get('Item', {})
                    # sales_countã‚’æ•°å€¤ã«å¤‰æ›ï¼ˆ'N/A'ã®å ´åˆã¯0ï¼‰
                    sales_count = item_info.get('salesCount', 'N/A')
                    if isinstance(sales_count, str) and sales_count != 'N/A':
                        try:
                            sales_count = int(sales_count)
                        except:
                            sales_count = 0
                    elif sales_count == 'N/A' or sales_count is None:
                        sales_count = 0
                    
                    trends_data.append({
                        'item_id': item_info.get('itemCode', ''),  # itemCodeã‚’item_idã¨ã—ã¦è¿½åŠ 
                        'title': item_info.get('itemName', ''),
                        'price': item_info.get('itemPrice', 0),
                        'review_count': item_info.get('reviewCount', 0),
                        'review_average': item_info.get('reviewAverage', 0),
                        'image_url': item_info.get('mediumImageUrls', [{}])[0].get('imageUrl', ''),
                        'url': item_info.get('itemUrl', ''),
                        'shop_name': item_info.get('shopName', ''),
                        'genre_id': item_info.get('genreId', ''),
                        'sales_rank': item_info.get('salesRank', 'N/A'),  # å£²ä¸Šãƒ©ãƒ³ã‚¯
                        'sales_count': sales_count  # å£²ä¸Šæ•°ï¼ˆæ•°å€¤ã«å¤‰æ›æ¸ˆã¿ï¼‰
                    })
                
                # å£²ä¸Šæ•°ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰ã€åŒã˜å ´åˆã¯ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã§ã‚½ãƒ¼ãƒˆ
                trends_data.sort(key=lambda x: (x.get('sales_count', 0), x.get('review_count', 0)), reverse=True)
                
                # ãƒ©ãƒ³ã‚¯ã‚’å†è¨­å®š
                for i, item in enumerate(trends_data, 1):
                    item['rank'] = i
                
                return {
                    'data': trends_data,
                    'status': 'success',
                    'source': 'æ¥½å¤©å•†å“ãƒ©ãƒ³ã‚­ãƒ³ã‚°API',
                    'total_count': len(trends_data)
                }
            else:
                logger.error(f"æ¥½å¤©ãƒ©ãƒ³ã‚­ãƒ³ã‚°APIã‚¨ãƒ©ãƒ¼: {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"æ¥½å¤©ãƒ©ãƒ³ã‚­ãƒ³ã‚°APIã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
            return None
    
    def _get_rakuten_search(self, genre_id=None, limit=25):
        """æ¥½å¤©å•†å“æ¤œç´¢APIã‚’ä½¿ç”¨"""
        try:
            # æ¥½å¤©å•†å“æ¤œç´¢API (æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³)
            url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20220601"
            params = {
                'applicationId': self.rakuten_app_id,
                'format': 'json',
                'sort': '+sales',  # å£²ä¸Šé †ï¼ˆã‚ˆã‚Šäººæ°—ã®å•†å“ï¼‰
                'hits': limit,
                'availability': 1,  # åœ¨åº«ã‚ã‚Š
                'field': 1  # å•†å“æƒ…å ±ã‚’è©³ç´°ã«
            }
            
            # ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆIDãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿è¿½åŠ 
            if self.rakuten_affiliate_id:
                params['affiliateId'] = self.rakuten_affiliate_id
            
            if genre_id:
                params['genreId'] = genre_id
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§äººæ°—ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆã‚ˆã‚Šä¸€èˆ¬çš„ãªå•†å“ã‚’å–å¾—ï¼‰
                params['keyword'] = 'äººæ°—'
            
            logger.debug(f"æ¥½å¤©APIãƒªã‚¯ã‚¨ã‚¹ãƒˆURL: {url}")
            logger.debug(f"æ¥½å¤©APIãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {params}")
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯
            self.rate_limiter.wait_if_needed()
            
            response = requests.get(url, params=params, timeout=10)
            logger.debug(f"æ¥½å¤©APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")
            logger.debug(f"æ¥½å¤©APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹: {response.text[:500]}...")
            
            if response.status_code == 200:
                data = response.json()
                items = data.get('Items', [])
                
                # ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
                trends_data = []
                for item in items:
                    item_info = item.get('Item', {})
                    trends_data.append({
                        'rank': len(trends_data) + 1,
                        'title': item_info.get('itemName', ''),
                        'price': item_info.get('itemPrice', 0),
                        'review_count': item_info.get('reviewCount', 0),
                        'review_average': item_info.get('reviewAverage', 0),
                        'image_url': item_info.get('mediumImageUrls', [{}])[0].get('imageUrl', ''),
                        'url': item_info.get('itemUrl', ''),
                        'shop_name': item_info.get('shopName', ''),
                        'genre_id': item_info.get('genreId', ''),
                        'sales_rank': item_info.get('salesRank', 'N/A'),  # å£²ä¸Šãƒ©ãƒ³ã‚¯
                        'sales_count': item_info.get('salesCount', 'N/A')  # å£²ä¸Šæ•°
                    })
                
                return {
                    'data': trends_data,
                    'status': 'success',
                    'source': 'æ¥½å¤©å•†å“æ¤œç´¢API',
                    'total_count': data.get('count', 0)
                }
            else:
                logger.error(f"æ¥½å¤©APIã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.text}")
                return {'error': f'æ¥½å¤©API ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}'}
                
        except Exception as e:
            return {'error': f'æ¥½å¤©ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}'}
    
    def get_genres(self):
        """æ¥½å¤©ã‚¸ãƒ£ãƒ³ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        if not self.rakuten_app_id:
            return {'error': 'æ¥½å¤©ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'}
        
        try:
            url = "https://app.rakuten.co.jp/services/api/IchibaGenre/Search/20140222"
            params = {
                'applicationId': self.rakuten_app_id,
                'format': 'json'
            }
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ãƒã‚§ãƒƒã‚¯
            self.rate_limiter.wait_if_needed()
            
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                return {
                    'data': data.get('children', []),
                    'status': 'success',
                    'source': 'æ¥½å¤©ã‚¸ãƒ£ãƒ³ãƒ«æ¤œç´¢API'
                }
            else:
                return {'error': f'æ¥½å¤©ã‚¸ãƒ£ãƒ³ãƒ«API ã‚¨ãƒ©ãƒ¼: {response.status_code}'}
                
        except Exception as e:
            return {'error': f'æ¥½å¤©ã‚¸ãƒ£ãƒ³ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}'}
    
    def get_rakuten_trends_summary(self):
        """æ¥½å¤©ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ¦‚è¦ã‚’å–å¾—"""
        return {
            'rakuten_api': {
                'available': bool(self.rakuten_app_id),
                'note': 'æ¥½å¤©å•†å“æ¤œç´¢API: äººæ°—å•†å“ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°é †',
                'features': [
                    'å•†å“æ¤œç´¢ãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°',
                    'ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥åˆ†é¡',
                    'ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ãƒ»è©•ä¾¡',
                    'ä¾¡æ ¼æƒ…å ±',
                    'ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ç”Ÿæˆ'
                ]
            },
            'limitations': [
                'å…¬å¼ãƒˆãƒ¬ãƒ³ãƒ‰APIãªã—',
                'ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°é †ã§ã®äººæ°—å•†å“å–å¾—',
                'ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰ã§ã¯ãªã„'
            ],
            'setup_required': [
                'æ¥½å¤©ãƒ‡ãƒ™ãƒ­ãƒƒãƒ‘ãƒ¼IDå–å¾—',
                'ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆIDå–å¾—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰'
            ]
        }
    
    def _should_refresh_cache(self, genre_id):
        """ä»Šæ—¥æ—¢ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã—ãŸã‹ãƒã‚§ãƒƒã‚¯ï¼ˆæœ5æ™‚ã‹ã‚‰å¤œ12æ™‚ã¾ã§ï¼‰"""
        try:
            from datetime import datetime
            import pytz
            # æ—¥æœ¬æ™‚é–“ã§ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—
            jst = pytz.timezone('Asia/Tokyo')
            now = datetime.now(jst)
            today = now.date()
            current_hour = now.hour
            
            # æ™‚é–“åˆ¶é™ï¼š5æ™‚ã‹ã‚‰24æ™‚ã¾ã§
            if not (5 <= current_hour < 24):
                logger.info(f"âš ï¸ æ™‚é–“å¤–ã§ã™ï¼ˆ{current_hour}æ™‚ï¼‰ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                return False
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æœ€å¾Œã®æ›´æ–°æ—¥æ™‚ã‚’å–å¾—
            with self.db.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        SELECT last_updated 
                        FROM cache_status 
                        WHERE cache_key = %s
                    """, ('rakuten_trends',))
                    
                    result = cursor.fetchone()
                    if result and result[0]:
                        last_refresh = result[0].date()
                        return last_refresh < today
                    return True  # åˆå›ã¯æ›´æ–°ã™ã‚‹
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°æ—¥æ™‚ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return True
    
    def get_from_cache(self, genre_id):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            return self.db.get_rakuten_trends_from_cache(genre_id)
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return None
    
    def save_to_cache(self, data, genre_id):
        """ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        try:
            self.db.save_rakuten_trends_to_cache(data, genre_id)
            # cache_statusãƒ†ãƒ¼ãƒ–ãƒ«ã‚‚æ›´æ–°
            self._update_refresh_time(genre_id or 'all')
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    
    def _update_refresh_time(self, genre_id):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°æ—¥æ™‚ã‚’è¨˜éŒ²"""
        try:
            from datetime import datetime
            import pytz
            # æ—¥æœ¬æ™‚é–“ã§ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—
            jst = pytz.timezone('Asia/Tokyo')
            now = datetime.now(jst)
            with self.db.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        INSERT INTO cache_status (cache_key, last_updated, data_count)
                        VALUES (%s, %s, %s)
                        ON CONFLICT (cache_key) 
                        DO UPDATE SET 
                            last_updated = EXCLUDED.last_updated,
                            data_count = EXCLUDED.data_count
                    """, ('rakuten_trends', now, 30))  # æ­£ã—ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ä½¿ç”¨
                    conn.commit()
        except Exception as e:
            logger.error(f"æ›´æ–°æ—¥æ™‚è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    
    def _get_cache_info(self, genre_id):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æƒ…å ±ã‚’å–å¾—"""
        try:
            with self.db.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        SELECT last_updated, data_count 
                        FROM cache_status 
                        WHERE cache_key = %s
                    """, ('rakuten_trends',))
                    
                    result = cursor.fetchone()
                    if result:
                        return {
                            'last_updated': result[0].isoformat() if result[0] else None,
                            'data_count': result[1] or 0
                        }
                    return {'last_updated': None, 'data_count': 0}
        except Exception as e:
            logger.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {'last_updated': None, 'data_count': 0}
